#!/usr/bin/env python3
"""
Kernel-GraphRAG Sentinel CLI
Main command-line interface for kernel code analysis.
"""

import sys
import os
from pathlib import Path
import click
import json
import logging

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import load_config, Config
from src.module_a.extractor import FunctionExtractor
from src.module_b.graph_store import Neo4jGraphStore
from src.module_b.ingestion import ingest_from_extractor
from src.module_c.test_mapper import TestMapper
from src.analysis.impact_analyzer import ImpactAnalyzer
from src.module_d.flow_ingestion import DataFlowIngestion

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@click.group()
@click.option('--config', '-c', type=click.Path(exists=True),
              help='Path to configuration YAML file')
@click.option('--kernel-root', '-k', type=click.Path(exists=True),
              help='Path to Linux kernel source root')
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging')
@click.pass_context
def cli(ctx, config, kernel_root, verbose):
    """
    Kernel-GraphRAG Sentinel - AI-powered Linux kernel code analysis tool.

    Analyzes kernel code structure, builds call graphs, maps test coverage,
    and provides impact analysis for code changes.
    """
    # Set logging level
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Load configuration
    ctx.ensure_object(dict)
    ctx.obj['config'] = load_config(config, kernel_root=kernel_root)
    ctx.obj['verbose'] = verbose


@cli.command()
@click.argument('subsystem')
@click.option('--skip-preprocessing', is_flag=True,
              help='Skip macro preprocessing (faster but less accurate)')
@click.option('--clear-db', is_flag=True,
              help='Clear database before ingestion')
@click.pass_context
def ingest(ctx, subsystem, skip_preprocessing, clear_db):
    """
    Extract and ingest kernel subsystem into Neo4j.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:

        kgraph ingest fs/ext4

        kgraph ingest fs/ext4 --clear-db

        kgraph ingest net/ipv4 --skip-preprocessing
    """
    config = ctx.obj['config']
    config.kernel.subsystem = subsystem

    click.echo(f"Ingesting {subsystem}...")
    click.echo(f"Kernel root: {config.kernel.root}")
    click.echo(f"Skip preprocessing: {skip_preprocessing}")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        # Clear database if requested
        if clear_db:
            click.confirm('‚ö†Ô∏è  This will delete all data in Neo4j. Continue?',
                          abort=True)
            store.clear_database()
            click.echo("Database cleared.")

        # Initialize schema
        store.initialize_schema()

        # Extract and ingest
        stats = ingest_from_extractor(
            config.kernel.root,
            subsystem,
            store,
            skip_preprocessing=skip_preprocessing
        )

        click.echo("\n" + "=" * 60)
        click.echo("INGESTION COMPLETE")
        click.echo("=" * 60)
        click.echo(json.dumps(stats, indent=2))

        # Show database statistics
        db_stats = store.get_statistics()
        click.echo("\nDatabase Statistics:")
        click.echo(json.dumps(db_stats, indent=2))


@cli.command()
@click.argument('subsystem')
@click.pass_context
def map_tests(ctx, subsystem):
    """
    Map KUnit tests to functions for a subsystem.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:

        kgraph map-tests fs/ext4

        kgraph map-tests fs/btrfs
    """
    config = ctx.obj['config']
    config.kernel.subsystem = subsystem

    click.echo(f"Mapping tests for {subsystem}...")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        mapper = TestMapper(store)

        stats = mapper.map_subsystem_tests(config.kernel.root, subsystem)

        click.echo("\n" + "=" * 60)
        click.echo("TEST MAPPING COMPLETE")
        click.echo("=" * 60)
        click.echo(json.dumps(stats, indent=2))


@cli.command()
@click.argument('function_name')
@click.option('--max-depth', '-d', default=3, type=int,
              help='Maximum call chain depth to analyze')
@click.option('--output', '-o', type=click.File('w'),
              help='Output file for report (default: stdout)')
@click.option('--llm', is_flag=True,
              help='Generate AI-powered natural language report using LLM')
@click.pass_context
def analyze(ctx, function_name, max_depth, output, llm):
    """
    Analyze the impact of modifying a function.

    FUNCTION_NAME: Name of the function to analyze

    Examples:

        kgraph analyze ext4_map_blocks

        kgraph analyze ext4_mb_new_blocks_simple --max-depth 5

        kgraph analyze ext4_inode_bitmap --output report.txt

        kgraph analyze ext4_map_blocks --llm  # AI-powered report
    """
    config = ctx.obj['config']

    click.echo(f"Analyzing impact for: {function_name}")
    click.echo(f"Max call depth: {max_depth}")
    if llm:
        click.echo(f"LLM provider: {config.llm.provider} ({config.llm.model})")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        analyzer = ImpactAnalyzer(store)

        impact = analyzer.analyze_function_impact(
            function_name,
            max_depth=max_depth,
            limit=config.analysis.max_results
        )

        if impact:
            # Generate LLM report if requested
            if llm:
                try:
                    from src.analysis.llm_reporter import LLMReporter, LLMConfig

                    click.echo("\nü§ñ Generating AI-powered report...")

                    llm_config = LLMConfig(
                        provider=config.llm.provider,
                        model=config.llm.model,
                        api_key=config.llm.api_key,
                        temperature=config.llm.temperature
                    )

                    # Pass graph_store for Mermaid diagram generation
                    reporter = LLMReporter(llm_config, graph_store=store)

                    # Convert ImpactResult to dict
                    impact_data = {
                        "file_path": impact.target_file,
                        "stats": impact.stats,
                        "direct_callers": impact.direct_callers,
                        "indirect_callers": impact.indirect_callers,
                        "direct_callees": impact.direct_callees,
                        "indirect_callees": impact.indirect_callees,
                        "direct_tests": impact.direct_tests,
                        "indirect_tests": impact.indirect_tests,
                        "risk_level": impact.stats.get('risk_level', 'UNKNOWN')
                    }

                    report = reporter.generate_impact_report(impact_data, function_name)

                except Exception as e:
                    click.echo(f"\n‚ùå LLM report generation failed: {e}")
                    click.echo("\nFalling back to standard report...\n")
                    report = analyzer.format_impact_report(impact, max_items=15)
            else:
                report = analyzer.format_impact_report(impact, max_items=15)

            if output:
                output.write(report)
                click.echo(f"\nReport written to {output.name}")
            else:
                click.echo("\n" + report)
        else:
            click.echo(f"‚ùå Function '{function_name}' not found in database")
            sys.exit(1)


@cli.command()
@click.argument('subsystem')
@click.option('--skip-preprocessing', is_flag=True,
              help='Skip macro preprocessing')
@click.option('--clear-db', is_flag=True,
              help='Clear database before ingestion')
@click.pass_context
def pipeline(ctx, subsystem, skip_preprocessing, clear_db):
    """
    Run complete analysis pipeline: ingest + map tests.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:

        kgraph pipeline fs/ext4

        kgraph pipeline fs/ext4 --clear-db
    """
    config = ctx.obj['config']
    config.kernel.subsystem = subsystem

    click.echo("=" * 60)
    click.echo(f"RUNNING PIPELINE FOR {subsystem}")
    click.echo("=" * 60)

    # Step 1: Ingest
    click.echo("\n[1/2] Ingesting subsystem...")
    ctx.invoke(ingest, subsystem=subsystem,
               skip_preprocessing=skip_preprocessing,
               clear_db=clear_db)

    # Step 2: Map tests
    click.echo("\n[2/2] Mapping tests...")
    ctx.invoke(map_tests, subsystem=subsystem)

    click.echo("\n" + "=" * 60)
    click.echo("PIPELINE COMPLETE")
    click.echo("=" * 60)
    click.echo(f"\n‚úÖ {subsystem} is now ready for analysis!")
    click.echo(f"\nTry: kgraph analyze <function_name>")


@cli.command()
@click.pass_context
def stats(ctx):
    """
    Show database statistics.

    Examples:

        kgraph stats
    """
    config = ctx.obj['config']

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        db_stats = store.get_statistics()

        click.echo("\n" + "=" * 60)
        click.echo("DATABASE STATISTICS")
        click.echo("=" * 60)
        click.echo(json.dumps(db_stats, indent=2))

        # Calculate totals
        total_nodes = sum(v for k, v in db_stats.items() if k.endswith('_count') and 'Function' in k or 'TestCase' in k or 'File' in k or 'Subsystem' in k)
        total_rels = sum(v for k, v in db_stats.items() if k.endswith('_count') and 'CALLS' in k or 'COVERS' in k or 'BELONGS_TO' in k or 'CONTAINS' in k)

        click.echo(f"\nTotal nodes: {total_nodes}")
        click.echo(f"Total relationships: {total_rels}")


@cli.command()
@click.option('--output', '-o', default='kgraph-config.yaml',
              help='Output configuration file path')
@click.pass_context
def init_config(ctx, output):
    """
    Generate example configuration file.

    Examples:

        kgraph init-config

        kgraph init-config --output my-config.yaml
    """
    config = ctx.obj.get('config') or Config.from_defaults()

    config.save_yaml(output)
    click.echo(f"‚úÖ Configuration file created: {output}")
    click.echo(f"\nEdit the file and run:")
    click.echo(f"  kgraph --config {output} pipeline fs/ext4")


@cli.command()
@click.option('--subsystem', '-s', help='Filter by subsystem')
@click.option('--min-callers', '-m', default=5, type=int,
              help='Minimum number of callers to show')
@click.option('--limit', '-l', default=20, type=int,
              help='Maximum number of results')
@click.pass_context
def top_functions(ctx, subsystem, min_callers, limit):
    """
    Show most frequently called functions.

    Examples:

        kgraph top-functions

        kgraph top-functions --subsystem ext4

        kgraph top-functions --min-callers 10 --limit 50
    """
    config = ctx.obj['config']

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        # Query top functions
        query = """
        MATCH (f:Function)<-[r:CALLS]-()
        """ + (f"WHERE f.subsystem = '{subsystem}'" if subsystem else "") + """
        WITH f, count(r) as call_count
        WHERE call_count >= $min_callers
        RETURN f.name as function_name, f.file_path as file_path,
               f.subsystem as subsystem, call_count
        ORDER BY call_count DESC
        LIMIT $limit
        """

        results = store.execute_query(query, {
            'min_callers': min_callers,
            'limit': limit
        })

        click.echo("\n" + "=" * 60)
        click.echo(f"TOP CALLED FUNCTIONS (min {min_callers} callers)")
        if subsystem:
            click.echo(f"Subsystem: {subsystem}")
        click.echo("=" * 60)

        for i, record in enumerate(results, 1):
            file_short = Path(record['file_path']).name if record['file_path'] else 'unknown'
            click.echo(f"{i:2}. {record['function_name']:40} "
                      f"({record['call_count']:3} calls) - {file_short}")


@cli.command('export-graph')
@click.argument('function_name')
@click.option('--format', type=click.Choice(['mermaid', 'dot', 'json']),
              default='mermaid', help='Export format')
@click.option('--output', '-o', help='Output file (stdout if not specified)')
@click.option('--max-depth', default=2, help='Maximum call graph depth')
@click.option('--direction', type=click.Choice(['callers', 'callees', 'both']),
              default='both', help='Graph direction')
@click.pass_context
def export_graph(ctx, function_name, format, output, max_depth, direction):
    """Export call graph visualization for a function.

    Exports call graph in various formats:
    - mermaid: Mermaid diagram (for GitHub/VS Code)
    - dot: Graphviz DOT format
    - json: JSON format for custom processing

    Examples:
        python3 src/main.py export-graph show_val_kb --format mermaid
        python3 src/main.py export-graph show_val_kb --format dot -o graph.dot
        python3 src/main.py export-graph show_val_kb --format json --direction callers
    """
    config = ctx.obj['config']

    from src.module_b.graph_store import Neo4jGraphStore
    from src.analysis.graph_exporter import GraphExporter

    try:
        # Initialize graph store
        store = Neo4jGraphStore(
            uri=config.neo4j.url,
            user=config.neo4j.user,
            password=config.neo4j.password
        )

        # Create exporter
        exporter = GraphExporter(store)

        # Export graph
        graph_output = exporter.export_callgraph(
            function_name=function_name,
            max_depth=max_depth,
            format=format,
            direction=direction
        )

        # Output result
        if output:
            with open(output, 'w') as f:
                f.write(graph_output)
            click.echo(f"‚úÖ Graph exported to {output} ({format} format)")

            if format == 'dot':
                click.echo(f"\nTo render: dot -Tpng {output} -o graph.png")
            elif format == 'mermaid':
                click.echo(f"\nView in GitHub, VS Code, or https://mermaid.live/")
        else:
            click.echo(graph_output)

    except Exception as e:
        click.echo(f"‚ùå Error exporting graph: {e}", err=True)
        raise click.Abort()


@cli.command('ingest-dataflow')
@click.argument('subsystem')
@click.option('--skip-preprocessing', is_flag=True,
              help='Skip macro preprocessing')
@click.pass_context
def ingest_dataflow(ctx, subsystem, skip_preprocessing):
    """
    Extract and ingest data flow information into Neo4j.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    This command extracts variable definitions, uses, and data flow edges
    from C code and stores them in Neo4j for advanced analysis.

    Examples:

        kgraph ingest-dataflow fs/ext4

        kgraph ingest-dataflow fs/ext4 --skip-preprocessing
    """
    config = ctx.obj['config']
    config.kernel.subsystem = subsystem

    click.echo(f"Ingesting data flow for {subsystem}...")
    click.echo(f"Kernel root: {config.kernel.root}")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        # Create data flow ingestion pipeline
        ingestion = DataFlowIngestion(store)

        # Setup schema
        click.echo("Setting up data flow schema...")
        ingestion.setup_schema()

        # Ingest subsystem directory
        subsystem_path = Path(config.kernel.root) / subsystem
        stats = ingestion.ingest_directory(str(subsystem_path), subsystem)

        click.echo("\n" + "=" * 60)
        click.echo("DATA FLOW INGESTION COMPLETE")
        click.echo("=" * 60)
        click.echo(json.dumps(stats, indent=2))

        # Get statistics
        click.echo("\nData Flow Statistics:")
        df_stats = ingestion.get_variable_statistics()
        click.echo(json.dumps(df_stats, indent=2))


@cli.command('dataflow')
@click.argument('variable_name')
@click.option('--function', '-f', help='Limit to specific function')
@click.option('--max-depth', '-d', default=3, type=int,
              help='Maximum flow chain depth')
@click.option('--direction', type=click.Choice(['forward', 'backward', 'both']),
              default='both', help='Flow direction to analyze')
@click.pass_context
def dataflow(ctx, variable_name, function, max_depth, direction):
    """
    Analyze data flow for a variable.

    VARIABLE_NAME: Name of the variable to trace

    This command shows how data flows through a variable, tracking
    assignments, function parameters, and return values.

    Examples:

        kgraph dataflow inode

        kgraph dataflow buffer --function ext4_read_block

        kgraph dataflow result --max-depth 5 --direction forward
    """
    config = ctx.obj['config']

    click.echo(f"Analyzing data flow for variable: {variable_name}")
    if function:
        click.echo(f"Function scope: {function}")
    click.echo(f"Max depth: {max_depth}")
    click.echo(f"Direction: {direction}")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        # Build query based on direction
        if direction == 'forward':
            # Variables that this variable flows TO
            query = """
            MATCH path = (v1:Variable {name: $var_name})-[:FLOWS_TO*1..$max_depth]->(v2:Variable)
            """ + (f"WHERE v1.scope = '{function}'" if function else "") + """
            RETURN v1.name as from_var, v1.scope as from_scope,
                   v2.name as to_var, v2.scope as to_scope,
                   length(path) as depth
            ORDER BY depth, to_var
            LIMIT 50
            """
        elif direction == 'backward':
            # Variables that flow TO this variable
            query = """
            MATCH path = (v1:Variable)-[:FLOWS_TO*1..$max_depth]->(v2:Variable {name: $var_name})
            """ + (f"WHERE v2.scope = '{function}'" if function else "") + """
            RETURN v1.name as from_var, v1.scope as from_scope,
                   v2.name as to_var, v2.scope as to_scope,
                   length(path) as depth
            ORDER BY depth, from_var
            LIMIT 50
            """
        else:  # both
            query = """
            MATCH path = (v1:Variable)-[:FLOWS_TO*1..$max_depth]-(v2:Variable)
            WHERE v1.name = $var_name OR v2.name = $var_name
            """ + (f"AND (v1.scope = '{function}' OR v2.scope = '{function}')" if function else "") + """
            RETURN v1.name as from_var, v1.scope as from_scope,
                   v2.name as to_var, v2.scope as to_scope,
                   length(path) as depth
            ORDER BY depth, from_var, to_var
            LIMIT 50
            """

        results = store.execute_query(query, {
            'var_name': variable_name,
            'max_depth': max_depth
        })

        if not results:
            click.echo(f"\n‚ùå No data flows found for variable '{variable_name}'")
            click.echo("\nTip: Make sure you've run 'kgraph ingest-dataflow <subsystem>' first")
            sys.exit(1)

        click.echo("\n" + "=" * 60)
        click.echo(f"DATA FLOW ANALYSIS: {variable_name}")
        click.echo("=" * 60)

        for record in results:
            depth_indicator = "  " * record['depth']
            click.echo(f"{depth_indicator}{record['from_var']} ({record['from_scope']}) "
                      f"‚Üí {record['to_var']} ({record['to_scope']}) "
                      f"[depth: {record['depth']}]")

        click.echo(f"\nTotal flows: {len(results)}")

        # Show additional variable info
        var_query = """
        MATCH (v:Variable {name: $var_name})
        RETURN v.name as name, v.type as type, v.scope as scope,
               v.is_parameter as is_param, v.is_pointer as is_ptr,
               v.file_path as file
        LIMIT 10
        """
        var_results = store.execute_query(var_query, {'var_name': variable_name})

        if var_results:
            click.echo("\n" + "=" * 60)
            click.echo(f"VARIABLE DEFINITIONS: {variable_name}")
            click.echo("=" * 60)

            for var in var_results:
                file_short = Path(var['file']).name if var['file'] else 'unknown'
                param_marker = " [param]" if var['is_param'] else ""
                ptr_marker = " [ptr]" if var['is_ptr'] else ""
                click.echo(f"  {var['type']} {var['name']} in {var['scope']}{param_marker}{ptr_marker}")
                click.echo(f"    File: {file_short}")


# ==================== CVE Commands ====================

@cli.group()
@click.pass_context
def cve(ctx):
    """CVE impact analysis commands."""
    pass


@cve.command('import')
@click.argument('source')
@click.option('--description', '-d', type=str,
              help='CVE description text (if SOURCE is a CVE ID)')
@click.option('--severity', '-s', type=click.Choice(['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']),
              default='MEDIUM', help='CVE severity level')
@click.option('--cvss', type=float, default=0.0, help='CVSS score (0-10)')
@click.pass_context
def cve_import(ctx, source, description, severity, cvss):
    """
    Import CVE from NVD JSON file or CVE ID with description.

    SOURCE: NVD JSON file path or CVE ID (e.g., CVE-2024-1234)

    Examples:

        # Import from NVD JSON file
        kgraph cve import nvd-2024.json

        # Import from CVE ID with description
        kgraph cve import CVE-2024-1234 -d "Buffer overflow in ext4_writepages" -s CRITICAL --cvss 9.8
    """
    config = ctx.obj['config']

    from src.module_e.cve_importer import CVEImporter

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        importer = CVEImporter(store, config.llm)

        # Check if source is a file or CVE ID
        if Path(source).exists():
            # Import from JSON file
            click.echo(f"Importing CVEs from {source}...")
            cves = importer.import_from_nvd_json(source)
            click.echo(f"‚úÖ Imported {len(cves)} CVEs")
        else:
            # Import from CVE ID
            if not description:
                click.echo("‚ùå Error: --description is required when importing by CVE ID", err=True)
                raise click.Abort()

            click.echo(f"Importing CVE {source}...")
            cve = importer.import_cve_from_text(
                source,
                description,
                metadata={'severity': severity, 'cvss_score': cvss}
            )

            if cve:
                click.echo(f"‚úÖ Imported CVE {source}")
                click.echo(f"   Function: {cve.affected_function}")
                click.echo(f"   Type: {cve.vulnerability_type}")
            else:
                click.echo(f"‚ùå Failed to import CVE {source}")
                raise click.Abort()


@cve.command('impact')
@click.argument('cve_id')
@click.option('--max-depth', type=int, default=5, help='Max depth for call chain traversal')
@click.pass_context
def cve_impact(ctx, cve_id, max_depth):
    """
    Analyze the impact of a CVE.

    CVE_ID: CVE identifier (e.g., CVE-2024-1234)

    Examples:

        kgraph cve impact CVE-2024-1234

        kgraph cve impact CVE-2024-1234 --max-depth 10
    """
    config = ctx.obj['config']

    from src.module_e.impact_analyzer import CVEImpactAnalyzer

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        analyzer = CVEImpactAnalyzer(store)

        click.echo(f"Analyzing impact for {cve_id}...")
        impact = analyzer.analyze_cve_impact(cve_id, max_depth=max_depth)

        if impact:
            report = analyzer.format_impact_report(impact)
            click.echo(report)
        else:
            click.echo(f"‚ùå CVE {cve_id} not found", err=True)
            raise click.Abort()


@cve.command('check')
@click.argument('cve_id')
@click.option('--kernel-version', '-k', required=True, type=str,
              help='Kernel version to check (e.g., 5.15, 6.1)')
@click.pass_context
def cve_check(ctx, cve_id, kernel_version):
    """
    Check if CVE affects a specific kernel version.

    CVE_ID: CVE identifier (e.g., CVE-2024-1234)

    Examples:

        kgraph cve check CVE-2024-1234 -k 5.15

        kgraph cve check CVE-2024-1234 --kernel-version 6.1
    """
    config = ctx.obj['config']

    from src.module_e.version_checker import VersionChecker

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        checker = VersionChecker(store, config.kernel.root)

        click.echo(f"Checking {cve_id} for kernel {kernel_version}...")
        result = checker.check_cve_version(cve_id, kernel_version)

        if result:
            report = checker.format_version_report(result)
            click.echo(report)
        else:
            click.echo(f"‚ùå Failed to check CVE {cve_id}", err=True)
            raise click.Abort()


@cve.command('test-gaps')
@click.argument('cve_id')
@click.pass_context
def cve_test_gaps(ctx, cve_id):
    """
    Analyze test coverage gaps for a CVE.

    CVE_ID: CVE identifier (e.g., CVE-2024-1234)

    Examples:

        kgraph cve test-gaps CVE-2024-1234
    """
    config = ctx.obj['config']

    from src.module_e.test_coverage import CVETestCoverage

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        analyzer = CVETestCoverage(store)

        click.echo(f"Analyzing test coverage for {cve_id}...")
        analysis = analyzer.analyze_cve_test_coverage(cve_id)

        if analysis:
            report = analyzer.format_coverage_report(analysis)
            click.echo(report)
        else:
            click.echo(f"‚ùå Failed to analyze test coverage for {cve_id}", err=True)
            raise click.Abort()


@cve.command('report')
@click.argument('cve_id')
@click.option('--kernel-version', '-k', type=str, help='Kernel version to check')
@click.option('--output', '-o', type=click.Path(), help='Output file (markdown)')
@click.pass_context
def cve_report(ctx, cve_id, kernel_version, output):
    """
    Generate a comprehensive CVE impact report.

    CVE_ID: CVE identifier (e.g., CVE-2024-1234)

    Examples:

        kgraph cve report CVE-2024-1234

        kgraph cve report CVE-2024-1234 -k 5.15

        kgraph cve report CVE-2024-1234 -k 5.15 -o report.md
    """
    config = ctx.obj['config']

    from src.module_e.cve_reporter import CVEReporter

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        reporter = CVEReporter(store, config.kernel.root)

        click.echo(f"Generating report for {cve_id}...")
        report = reporter.generate_cve_report(cve_id, kernel_version)

        if report:
            if output:
                with open(output, 'w') as f:
                    f.write(report)
                click.echo(f"‚úÖ Report saved to {output}")
            else:
                click.echo(report)
        else:
            click.echo(f"‚ùå Failed to generate report for {cve_id}", err=True)
            raise click.Abort()


@cve.command('backport-checklist')
@click.option('--kernel-version', '-k', required=True, type=str,
              help='Target kernel version')
@click.option('--severity', '-s', type=click.Choice(['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']),
              multiple=True, help='Filter by severity (can be specified multiple times)')
@click.option('--subsystem', type=str, help='Filter by subsystem (e.g., fs/ext4)')
@click.option('--output', '-o', type=click.Path(), help='Output file (markdown)')
@click.pass_context
def cve_backport_checklist(ctx, kernel_version, severity, subsystem, output):
    """
    Generate a backport checklist for CVEs.

    Examples:

        kgraph cve backport-checklist -k 5.15

        kgraph cve backport-checklist -k 5.15 -s CRITICAL -s HIGH

        kgraph cve backport-checklist -k 5.15 --subsystem fs/ext4 -o checklist.md
    """
    config = ctx.obj['config']

    from src.module_e.impact_analyzer import CVEImpactAnalyzer
    from src.module_e.cve_reporter import CVEReporter

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        # Get all CVEs
        impact_analyzer = CVEImpactAnalyzer(store)
        cves = impact_analyzer.get_all_cves()

        # Filter by severity
        if severity:
            cves = [c for c in cves if c.get('severity') in severity]

        # Filter by subsystem
        if subsystem:
            cves = [c for c in cves if subsystem in c.get('file_path', '')]

        if not cves:
            click.echo("No CVEs found matching criteria")
            return

        cve_ids = [c['id'] for c in cves]

        # Generate checklist
        reporter = CVEReporter(store, config.kernel.root)
        checklist = reporter.generate_backport_checklist(cve_ids, kernel_version, output)

        if not output:
            click.echo(checklist)


@cve.command('list')
@click.option('--severity', '-s', type=click.Choice(['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']),
              help='Filter by severity')
@click.option('--limit', '-l', type=int, default=20, help='Maximum number of CVEs to show')
@click.pass_context
def cve_list(ctx, severity, limit):
    """
    List all CVEs in the database.

    Examples:

        kgraph cve list

        kgraph cve list --severity CRITICAL

        kgraph cve list -s HIGH -s CRITICAL -l 50
    """
    config = ctx.obj['config']

    from src.module_e.impact_analyzer import CVEImpactAnalyzer

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        analyzer = CVEImpactAnalyzer(store)

        # Get CVEs
        if severity:
            cves = analyzer.get_cves_by_severity(severity)
        else:
            cves = analyzer.get_all_cves()

        # Display
        if cves:
            click.echo(f"\nFound {len(cves)} CVE(s)")
            click.echo("=" * 80)

            for cve in cves[:limit]:
                click.echo(f"\n{cve['id']}: {cve.get('affected_function', 'Unknown')}")
                click.echo(f"  Severity: {cve.get('severity', 'UNKNOWN')} (CVSS {cve.get('cvss_score', 0)})")
                click.echo(f"  Type: {cve.get('vulnerability_type', 'unknown')}")
                click.echo(f"  File: {cve.get('file_path', 'Unknown')}")

            if len(cves) > limit:
                click.echo(f"\n... and {len(cves) - limit} more")
        else:
            click.echo("No CVEs found")


# ==================== Log Coverage Commands ====================

@cli.group()
@click.pass_context
def logs(ctx):
    """Log coverage analysis commands."""
    pass


@logs.command('extract')
@click.argument('subsystem')
@click.option('--output', '-o', type=click.Path(), help='Output JSON file')
@click.pass_context
def logs_extract(ctx, subsystem, output):
    """
    Extract log statements from kernel subsystem.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:

        kgraph logs extract fs/ext4

        kgraph logs extract fs/ext4 -o logs.json
    """
    config = ctx.obj['config']

    from src.module_f.log_extractor import LogExtractor
    from pathlib import Path

    subsystem_path = Path(config.kernel.root) / subsystem

    if not subsystem_path.exists():
        click.echo(f"‚ùå Subsystem path not found: {subsystem_path}", err=True)
        raise click.Abort()

    click.echo(f"Extracting logs from {subsystem}...")

    extractor = LogExtractor()
    all_logs = []

    # Process all .c files in subsystem
    for c_file in subsystem_path.rglob('*.c'):
        try:
            logs = extractor.extract_from_file(str(c_file))
            all_logs.extend(logs)
            click.echo(f"  {c_file.name}: {len(logs)} logs")
        except Exception as e:
            logger.warning(f"Failed to extract logs from {c_file}: {e}")

    click.echo(f"\n‚úÖ Extracted {len(all_logs)} log statements")

    # Output results
    if output:
        import json
        output_data = [log.to_dict() for log in all_logs]
        with open(output, 'w') as f:
            json.dump(output_data, f, indent=2)
        click.echo(f"Logs saved to {output}")
    else:
        # Print summary
        from collections import Counter
        log_funcs = Counter([log.log_function for log in all_logs])
        click.echo("\nLog functions used:")
        for func, count in log_funcs.most_common():
            click.echo(f"  {func}: {count}")


@logs.command('coverage')
@click.argument('function')
@click.option('--file', '-f', type=click.Path(exists=True), help='C source file path')
@click.option('--suggest', is_flag=True, help='Show log placement suggestions')
@click.pass_context
def logs_coverage(ctx, function, file, suggest):
    """
    Analyze log coverage for a function.

    FUNCTION: Function name to analyze

    Examples:

        kgraph logs coverage ext4_writepages

        kgraph logs coverage ext4_writepages --suggest

        kgraph logs coverage ext4_writepages -f fs/ext4/inode.c --suggest
    """
    config = ctx.obj['config']

    from src.module_f.coverage_analyzer import CoverageAnalyzer
    from pathlib import Path

    if not file:
        click.echo("‚ùå Error: --file is required", err=True)
        raise click.Abort()

    click.echo(f"Analyzing log coverage for {function}...")

    analyzer = CoverageAnalyzer()
    source_code = Path(file).read_text(encoding='utf-8', errors='ignore')

    report = analyzer.analyze_function(source_code, function, file)

    # Print coverage report
    analyzer.print_coverage_report(report, verbose=True)

    # Show suggestions if requested
    if suggest and report.unlogged_paths:
        suggestions = analyzer.suggest_logs(report, source_code)
        analyzer.print_suggestions(suggestions)


@logs.command('gaps')
@click.argument('function')
@click.option('--file', '-f', type=click.Path(exists=True), required=True,
              help='C source file path')
@click.option('--suggest', is_flag=True, help='Show log placement suggestions')
@click.pass_context
def logs_gaps(ctx, function, file, suggest):
    """
    Show unlogged error paths (gaps) for a function.

    FUNCTION: Function name to analyze

    Examples:

        kgraph logs gaps ext4_writepages -f fs/ext4/inode.c

        kgraph logs gaps ext4_writepages -f fs/ext4/inode.c --suggest
    """
    config = ctx.obj['config']

    from src.module_f.coverage_analyzer import CoverageAnalyzer
    from pathlib import Path

    click.echo(f"Finding log gaps for {function}...")

    analyzer = CoverageAnalyzer()
    source_code = Path(file).read_text(encoding='utf-8', errors='ignore')

    report = analyzer.analyze_function(source_code, function, file)

    if not report.unlogged_paths:
        click.echo(f"\n‚úì No gaps found - {function} has 100% coverage!")
        return

    click.echo(f"\n{function}: {len(report.unlogged_paths)} unlogged error paths\n")

    for gap in report.unlogged_paths:
        error_info = f"{gap.path_type}"
        if gap.path_type == 'return' and gap.error_code:
            error_info += f" {gap.error_code}"
        elif gap.path_type == 'goto' and gap.goto_label:
            error_info += f" {gap.goto_label}"

        click.echo(f"  ‚úó Line {gap.line_number}: {error_info}")

    # Show suggestions if requested
    if suggest:
        suggestions = analyzer.suggest_logs(report, source_code)
        analyzer.print_suggestions(suggestions)


@logs.command('dmesg')
@click.argument('message')
@click.option('--subsystem', '-s', help='Limit to subsystem')
@click.pass_context
def logs_dmesg(ctx, message, subsystem):
    """
    Quick dmesg ‚Üí code lookup.

    MESSAGE: Error message from dmesg (or pattern)

    Examples:

        kgraph logs dmesg "ext4 writepage failed"

        kgraph logs dmesg "allocation failed" -s fs/ext4
    """
    config = ctx.obj['config']

    from src.module_f.log_search import LogSearch
    from src.module_f.log_extractor import LogExtractor
    from pathlib import Path

    click.echo(f"Searching for: {message}")

    # Extract logs from subsystem
    extractor = LogExtractor()
    all_logs = []

    if subsystem:
        subsystem_path = Path(config.kernel.root) / subsystem
        for c_file in subsystem_path.rglob('*.c'):
            try:
                logs = extractor.extract_from_file(str(c_file))
                all_logs.extend(logs)
            except Exception as e:
                logger.warning(f"Failed to extract logs from {c_file}: {e}")
    else:
        click.echo("‚ùå Error: --subsystem is required for dmesg search", err=True)
        click.echo("Tip: Use --subsystem to limit search scope and improve performance")
        raise click.Abort()

    # Build search index
    search = LogSearch()
    search.index_logs(all_logs)

    # Search for matches
    matches = search.search(message)

    # Print results
    search.print_search_results(matches, message)


@logs.command('report')
@click.argument('subsystem')
@click.option('--output', '-o', type=click.Path(), help='Output markdown file')
@click.option('--json', is_flag=True, help='Output JSON format')
@click.pass_context
def logs_report(ctx, subsystem, output, json):
    """
    Generate log coverage report for a subsystem.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:

        kgraph logs report fs/ext4

        kgraph logs report fs/ext4 -o coverage_report.md

        kgraph logs report fs/ext4 --json -o report.json
    """
    config = ctx.obj['config']

    from src.module_f.coverage_analyzer import CoverageAnalyzer
    from src.module_f.redundant_detector import RedundantDetector
    from src.module_f.log_reporter import LogReporter
    from pathlib import Path

    subsystem_path = Path(config.kernel.root) / subsystem

    if not subsystem_path.exists():
        click.echo(f"‚ùå Subsystem path not found: {subsystem_path}", err=True)
        raise click.Abort()

    click.echo(f"Generating log coverage report for {subsystem}...")

    analyzer = CoverageAnalyzer()
    redundant_detector = RedundantDetector()
    reporter = LogReporter()

    all_reports = {}
    all_logs = []
    all_suggestions = {}

    # Analyze all .c files
    for c_file in subsystem_path.rglob('*.c'):
        try:
            source_code = c_file.read_text(encoding='utf-8', errors='ignore')

            # Extract logs
            from src.module_f.log_extractor import LogExtractor
            extractor = LogExtractor()
            logs = extractor.extract_from_file(str(c_file))
            all_logs.extend(logs)

            # Analyze coverage per function
            file_reports = analyzer.analyze_file(str(c_file))
            all_reports.update(file_reports)

        except Exception as e:
            logger.warning(f"Failed to analyze {c_file}: {e}")

    # Generate suggestions for functions with gaps
    for func_name, report in all_reports.items():
        if report.unlogged_paths:
            source_code = Path(report.file_path).read_text(encoding='utf-8', errors='ignore')
            suggestions = analyzer.suggest_logs(report, source_code)
            if suggestions:
                all_suggestions[func_name] = suggestions

    # Detect redundant logs
    redundant_logs = redundant_detector.find_redundant_logs(all_logs)

    # Generate report
    if json:
        report_json = reporter.generate_json_report(all_reports, all_suggestions, redundant_logs)
        import json
        report_text = json.dumps(report_json, indent=2)
    else:
        report_text = reporter.generate_markdown_report(
            all_reports,
            all_suggestions,
            redundant_logs,
            title=f"Log Coverage Report: {subsystem}"
        )

    # Output
    if output:
        with open(output, 'w') as f:
            f.write(report_text)
        click.echo(f"‚úÖ Report saved to {output}")
    else:
        click.echo("\n" + report_text)


# ==================== Git History Commands ====================

@cli.group()
@click.pass_context
def git(ctx):
    """Git history integration commands."""
    pass


@git.command('ingest')
@click.option('--since', help='Start date (e.g., 2020-01-01)')
@click.option('--limit', '-l', default=1000, type=int, help='Max commits to extract')
@click.option('--branch', default='HEAD', help='Branch to analyze')
@click.pass_context
def git_ingest(ctx, since, limit, branch):
    """
    Extract and store git metadata in Neo4j.

    Examples:
        kgraph git ingest
        kgraph git ingest --since 2020-01-01 --limit 5000
    """
    config = ctx.obj['config']

    from src.module_g.git_extractor import GitExtractor

    click.echo(f"Extracting git metadata from {config.kernel.root}...")

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        extractor = GitExtractor(config.kernel.root)

        # Extract commits
        commits = extractor.extract_commits(
            since=since,
            limit=limit,
            branch=branch
        )

        click.echo(f"‚úÖ Extracted {len(commits)} commits")

        # Store in Neo4j (placeholder - would need actual implementation)
        # for commit in commits:
        #     store.upsert_git_commit(commit)


@git.command('log')
@click.argument('function')
@click.option('--limit', '-l', default=20, help='Max commits to show')
@click.pass_context
def git_log(ctx, function, limit):
    """
    Show git commit history for a function.

    FUNCTION: Function name

    Examples:
        kgraph git log ext4_writepages
        kgraph git log ext4_writepages --limit 50
    """
    config = ctx.obj['config']

    from src.module_g.git_extractor import GitExtractor
    from src.module_g.evolution_tracker import EvolutionTracker

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        extractor = GitExtractor(config.kernel.root)
        tracker = EvolutionTracker(store, extractor)

        history = tracker.track_function_history(function)

        if not history:
            click.echo(f"No history found for {function}")
            return

        click.echo(f"\n{'='*60}")
        click.echo(f"Git History: {function}")
        click.echo(f"{'='*60}\n")

        for i, entry in enumerate(history[:limit], 1):
            click.echo(f"{i}. {entry['date']} | {entry['commit_hash']}")
            click.echo(f"   Author: {entry['author']}")
            click.echo(f"   Message: {entry['message'][:60]}...")
            click.echo(f"   Complexity: {entry['complexity']}")
            click.echo()


@git.command('blame')
@click.argument('location')
@click.option('--function', '-f', help='Function name (if known)')
@click.pass_context
def git_blame(ctx, location, function):
    """
    Show git blame information with code analysis context.

    LOCATION: File and line (e.g., fs/ext4/inode.c:2145)

    Examples:
        kgraph git blame fs/ext4/inode.c:2145
        kgraph git blame fs/ext4/inode.c:2145 --function ext4_writepages
    """
    config = ctx.obj['config']

    # Parse file:line
    parts = location.rsplit(':', 1)
    if len(parts) != 2:
        click.echo("‚ùå Invalid location format. Use: file:line")
        raise click.Abort()

    file_path, line_num = parts
    line_num = int(line_num)

    from src.module_g.blame_mapper import BlameMapper

    mapper = BlameMapper(config.kernel.root)
    blame_info = mapper.get_commit_for_line(file_path, line_num)

    if not blame_info:
        click.echo(f"‚ùå No blame info for {location}")
        raise click.Abort()

    click.echo(f"\n{'='*60}")
    click.echo(f"Blame: {location}")
    click.echo(f"{'='*60}\n")
    click.echo(f"Commit: {blame_info['commit_hash']}")
    click.echo(f"Author: {blame_info['author']}")
    click.echo(f"Date: {blame_info['date']}")
    click.echo(f"Summary: {blame_info.get('summary', 'N/A')}")

    if function:
        # Get function blame context
        from src.module_a.parser import CParser
        try:
            parser = CParser()
            full_path = str(Path(config.kernel.root) / file_path)
            source_code = Path(full_path).read_text(encoding='utf-8', errors='ignore')
            tree = parser.parse(source_code)

            # Find function (simplified - would need proper AST traversal)
            click.echo(f"\nFunction: {function}")
        except:
            pass


@git.command('commit')
@click.argument('commit_hash')
@click.option('--analyze', '-a', is_flag=True, help='Perform impact analysis')
@click.pass_context
def git_commit(ctx, commit_hash, analyze):
    """
    Show detailed analysis of a commit.

    COMMIT_HASH: Full or short commit hash

    Examples:
        kgraph git commit 7a8b9c1d
        kgraph git commit 7a8b9c1d --analyze
    """
    config = ctx.obj['config']

    from src.module_g.git_extractor import GitExtractor
    from src.module_g.commit_analyzer import CommitAnalyzer

    if analyze:
        with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                              config.neo4j.password) as store:
            extractor = GitExtractor(config.kernel.root)
            analyzer = CommitAnalyzer(store, extractor)

            analysis = analyzer.analyze_commit(commit_hash)

            if not analysis:
                click.echo(f"‚ùå Commit {commit_hash} not found")
                raise click.Abort()

            commit_info = analysis['commit_info']
            click.echo(f"\n{'='*60}")
            click.echo(f"Commit: {commit_info['hash']} - {commit_info['title']}")
            click.echo(f"{'='*60}\n")
            click.echo(f"Author: {commit_info['author']} <{commit_info.get('author_email', '')}>")
            click.echo(f"Date: {commit_info['date']}")
            click.echo(f"Branch: {commit_info['branch']}")
            click.echo(f"\nFiles changed: {commit_info['files_changed']} (+{commit_info['insertions']}, -{commit_info['deletions']})")

            functions = analysis['functions_modified']
            if functions:
                click.echo(f"\nFunctions modified: {len(functions)}")

                for func in functions[:10]:
                    risk = func.get('risk_level', 'UNKNOWN')
                    click.echo(f"\n  {func['function_name']} - {risk}")
                    if 'impact' in func:
                        impact = func['impact']
                        click.echo(f"    ‚Üí Callers: {impact.get('callers', 0)}, Callees: {impact.get('callees', 0)}")

                if len(functions) > 10:
                    click.echo(f"\n  ... and {len(functions) - 10} more")

            risk = analysis['risk_summary']
            if risk:
                click.echo(f"\nRisk Summary:")
                click.echo(f"  High: {risk['high_risk_count']}, Medium: {risk['medium_risk_count']}, Low: {risk['low_risk_count']}")

                for rec in risk.get('recommendations', []):
                    click.echo(f"  {rec}")


@git.command('timeline')
@click.argument('function')
@click.option('--format', '-f', type=click.Choice(['ascii', 'markdown', 'mermaid']),
              default='ascii', help='Timeline format')
@click.option('--stats', is_flag=True, help='Include trend statistics')
@click.pass_context
def git_timeline(ctx, function, format, stats):
    """
    Show visual timeline of function evolution.

    FUNCTION: Function name

    Examples:
        kgraph git timeline ext4_writepages
        kgraph git timeline ext4_writepages --format mermaid
        kgraph git timeline ext4_writepages --stats
    """
    config = ctx.obj['config']

    from src.module_g.git_extractor import GitExtractor
    from src.module_g.evolution_tracker import EvolutionTracker
    from src.module_g.timeline_generator import TimelineGenerator

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        extractor = GitExtractor(config.kernel.root)
        tracker = EvolutionTracker(store, extractor)
        generator = TimelineGenerator(store, tracker)

        timeline = generator.generate_function_timeline(function, format)
        click.echo(timeline)

        if stats:
            trend = tracker.calculate_complexity_trend(function)
            trend_output = generator.format_complexity_trend(function, trend)
            click.echo(trend_output)


@git.command('authors')
@click.argument('subsystem')
@click.option('--limit', '-l', default=20, help='Max authors to show')
@click.pass_context
def git_authors(ctx, subsystem, limit):
    """
    Show code ownership metrics for a subsystem.

    SUBSYSTEM: Relative path to subsystem (e.g., fs/ext4)

    Examples:
        kgraph git authors fs/ext4
        kgraph git authors fs/ext4 --limit 50
    """
    config = ctx.obj['config']

    from src.module_g.author_analytics import AuthorAnalytics

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        analytics = AuthorAnalytics(store)

        owners = analytics.get_subsystem_owners(subsystem)

        if not owners:
            click.echo(f"No ownership data found for {subsystem}")
            return

        click.echo(f"\n{'='*60}")
        click.echo(f"Code Ownership: {subsystem}")
        click.echo(f"{'='*60}\n")

        for i, owner in enumerate(owners[:limit], 1):
            click.echo(f"{i}. {owner['author']} ({owner.get('email', 'N/A')})")
            click.echo(f"   Commits: {owner['commits']}")
            click.echo(f"   Lines: +{owner.get('lines_added', 0)}, -{owner.get('lines_removed', 0)}")
            if 'ownership_pct' in owner:
                click.echo(f"   Ownership: {owner['ownership_pct']}%")
            click.echo()


@git.command('bisect-helper')
@click.argument('bug_description')
@click.option('--function', '-f', help='Function to analyze')
@click.pass_context
def git_bisect_helper(ctx, bug_description, function):
    """
    Get analysis help during git bisect.

    BUG_DESCRIPTION: Description of the bug

    Examples:
        kgraph git bisect-helper "ext4: writepage hang on ENOMEM"
        kgraph git bisect-helper "ext4: writepage hang" --function ext4_writepages
    """
    config = ctx.obj['config']

    from src.module_g.bisect_helper import BisectHelper

    with Neo4jGraphStore(config.neo4j.url, config.neo4j.user,
                          config.neo4j.password) as store:
        helper = BisectHelper(store, config.kernel.root)

        analysis = helper.analyze_bisect_state(bug_description, function)

        click.echo(f"\n{'='*60}")
        click.echo(f"Bisect Helper: {bug_description}")
        click.echo(f"{'='*60}\n")

        click.echo(f"Function: {analysis['function_name']}")
        click.echo(f"Hypothesis: {analysis['hypothesis']}\n")

        click.echo("Checkpoints:")
        for checkpoint in analysis['checkpoints']:
            status = "‚úì" if checkpoint['result'] else "‚úó"
            click.echo(f"  {status} {checkpoint['check']}")

        click.echo(f"\nVerdict: {analysis['verdict']}")
        click.echo(f"Reason: {analysis['reason']}")


# ==================== Version Command ====================

@cli.command()
@click.pass_context
def version(ctx):
    """Show version information."""
    click.echo("Kernel-GraphRAG Sentinel v0.6.0")
    click.echo("AI-powered Linux kernel code analysis")
    click.echo("\nv0.1.0 - Core functionality complete")
    click.echo("  ‚úÖ Phase 1: Environment Setup")
    click.echo("  ‚úÖ Phase 2: C Code Parser")
    click.echo("  ‚úÖ Phase 3: Neo4j Graph Store")
    click.echo("  ‚úÖ Phase 4: KUnit Test Mapper")
    click.echo("  ‚úÖ Phase 5: Impact Analysis")
    click.echo("  ‚úÖ Phase 6: CLI Interface")
    click.echo("  ‚úÖ Phase 7: Visualization & Documentation")
    click.echo("\nv0.2.0 - Data Flow Analysis")
    click.echo("  ‚úÖ Module D: Variable tracking & flow analysis")
    click.echo("  ‚úÖ Neo4j data flow ingestion")
    click.echo("  ‚úÖ CLI commands: ingest-dataflow, dataflow")
    click.echo("\nv0.4.0 - CVE Impact Analysis")
    click.echo("  ‚úÖ Module E: CVE importer & parser")
    click.echo("  ‚úÖ CVE impact analysis engine")
    click.echo("  ‚úÖ Version checking & backport detection")
    click.echo("  ‚úÖ Test coverage analysis for CVEs")
    click.echo("  ‚úÖ CVE reporting & backport checklists")
    click.echo("  ‚úÖ CLI commands: cve import, impact, check, report, ...")
    click.echo("\nv0.5.0 - Log Coverage Analyzer")
    click.echo("  ‚úÖ Module F: Log extraction & analysis")
    click.echo("  ‚úÖ Error path detection & coverage calculation")
    click.echo("  ‚úÖ Gap detection with suggestions")
    click.echo("  ‚úÖ Redundant log detection")
    click.echo("  ‚úÖ dmesg ‚Üí code lookup")
    click.echo("  ‚úÖ Coverage reporting (markdown/JSON)")
    click.echo("  ‚úÖ CLI commands: logs extract, coverage, gaps, dmesg, report")
    click.echo("\nv0.6.0 - Git History Integration")
    click.echo("  ‚úÖ Module G: Git metadata extraction")
    click.echo("  ‚úÖ Git blame integration with code context")
    click.echo("  ‚úÖ Commit change analysis with impact")
    click.echo("  ‚úÖ Function evolution tracking")
    click.echo("  ‚úÖ Visual timeline generation")
    click.echo("  ‚úÖ Code ownership metrics")
    click.echo("  ‚úÖ Git bisect assistance")
    click.echo("  ‚úÖ CLI commands: git ingest, log, blame, commit, timeline, authors, bisect-helper")


def main():
    """Entry point for the CLI."""
    cli(obj={})


if __name__ == '__main__':
    main()
